# ChatBot

使用环境：pyctr，python 3.6.8 + tf 1.14.0

主要参考 http://www.shareditor.com/ 自己动手做聊天机器人 系列

## 相关依赖

```
pip install nltk
pip install --upgrade certifi
pip install pynlpir
```

## 语料

+ https://github.com/candlewill/Dialog_Corpus，具体看说明，比较好的是 ChatterBot，小黄鸡，白鹭时代，保险行业
+ https://github.com/codemayq/chinese_chatbot_corpus，具体看说明

## 评测方法

deltaBLEU

## 重点说明

关键技术

1. 海量文本知识表示：网络文本资源获取、机器学习方法、大规模语义计算和推理、知识表示体系、知识库构建；
2. 问句解析：中文分词、词性标注、实体标注、概念类别标注、句法分析、语义分析、逻辑结构标注、指代消解、关联关系标注、问句分类（简单问句还是复杂问句、实体型还是段落型还是篇章级问题）、答案类别确定；
3. 答案生成与过滤：候选答案抽取、关系推演（并列关系还是递进关系还是因果关系）、吻合程度判断、噪声过滤

聊天机器人的技术可以分成四种类型

1. 基于检索的技术：无法处理推理
2. 基于模式匹配的技术：无法涵盖各种情景
3. 基于统计翻译模型的技术：简单粗暴，但匹配率低
4. 基于自然语言理解的技术：未来方向！

## 依存关系

主要使用哈工大的 LTP 平台 http://www.ltp-cloud.com/

依存句法分析和语义分析相结合使用，对对方说的话进行依存和语义分析后，一方面可以让计算机理解句子的含义，从而匹配到最合适的回答，另外如果有已经存在的依存、语义分析结果，还可以通过置信度匹配来实现聊天回答。

依存关系的五条公理

1. 一个句子中只有一个成分是独立的
2. 其他成分直接依存于某一成分
3. 任何一个成分都不能依存于两个或两个以上的成分
4. 如果A成分直接依存于B成分，而C成分在句子中位于A和B之间，那么C或者直接依存于B，或者直接依存于A和B之间的某一成分
5. 中心成分左右两面的其他成分相互不发生关系

LTP依存关系标记

+ 主谓关系 SBV subject-verb 我送她一束花 (我 <-- 送)
+ 动宾关系 VOB 直接宾语，verb-object 我送她一束花 (送 --> 花)
+ 间宾关系 IOB 间接宾语，indirect-object 我送她一束花 (送 --> 她)
+ 前置宾语 FOB 前置宾语，fronting-object 他什么书都读 (书 <-- 读)
+ 兼语 DBL double 他请我吃饭 (请 --> 我)
+ 定中关系 ATT attribute 红苹果 (红 <-- 苹果)
+ 状中结构 ADV adverbial 非常美丽 (非常 <-- 美丽)
+ 动补结构 CMP complement 做完了作业 (做 --> 完)
+ 并列关系 COO coordinate 大山和大海 (大山 --> 大海)
+ 介宾关系 POB preposition-object 在贸易区内 (在 --> 内)
+ 左附加关系 LAD left adjunct 大山和大海 (和 <-- 大海)
+ 右附加关系 RAD right adjunct 孩子们 (孩子 --> 们)
+ 独立结构 IS independent structure 两个单句在结构上彼此独立
+ 核心关系 HED head 指整个句子的核心

## 语言模型

语言模型是根据语言客观事实而进行的语言抽象数学建模。说白了，就是找到一个数学模型，让它来解释自然语言的事实。

业界目前比较认可而且有效的语言模型是n元语法模型(n-gram model)，它本质上是马尔可夫模型。工程上n=3用的是最多的，因为n越大约束信息越多，n越小可靠性更高

## 爬虫

爬虫采用 scrapy

## 分词

+ jieba：词表+字构词
+ ik 分词器：基于词表最短路径切词
+ ltp 云平台：机器学习 + 词表

目前最先进：结合了基于词表和由字构词并且充分利用统计学习的方法

## 概率图

有向图模型和无向图模型，顾名思义，就是图里面的边是否有方向。那么什么样的模型的边有方向，而什么样的没方向呢？这个很好想到，有方向的表达的是一种推演关系，也就是在A的前提下出现了B，这种模型又叫做生成式模型。而没有方向表达的是一种“这样就对了”的关系，也就是A和B同时存在就对了，这种模型又叫做判别式模型。生成式模型一般用联合概率计算(因为我们知道A的前提了，可以算联合概率)，判别式模型一般用条件概率计算(因为我们不知道前提，所以只能"假设"A条件下B的概率)。生成式模型的代表是：n元语法模型、隐马尔可夫模型、朴素贝叶斯模型等。判别式模型的代表是：最大熵模型、支持向量机、条件随机场、感知机模型等

贝叶斯网络能够在已知有限的、不完整的、不确定信息条件下进行学习推理，所以广泛应用在故障诊断、维修决策、汉语自动分词、词义消歧等问题上

场表示取值范围，随机场表示随机变量有取值范围，也就是每个随机变量有固定的取值，条件指的是随机变量的取值由一定的条件概率决定，而这里的条件来自于我们有一些观察值，这是它区别于其他随机场的地方。条件随机场也可以看做是一个无向图模型，它特殊就特殊在给定观察序列X时某个特定的标记序列Y的概率是一个指数函数exp(∑λt+∑μs)，其中t是转移函数，s是状态函数，我们需要训练的是λ和μ。条件随机场主要应用在标注和切分有序数据上，尤其在自然语言处理、生物信息学、机器视觉、网络智能等方面

## 词性标注

词性标注的方法主要有基于统计和基于规则的方法，另外还包括后期校验的过程。词性标注是帮助计算机理解语言含义的关键，有了词性标注，我们才可以进一步确定句法和语义，才有可能让机器理解语言的含义，才有可能实现聊天机器人的梦想

## 句法分析树

句法分析树生成算法是基于统计学习的原理，根据大量标注的语料库（树库），通过机器学习算法得出非终结符、终结符、规则集及其概率参数，然后利用动态规划算法生成每一句话的句法分析树，在句法分析树生成过程中如果遇到多种树结构，选择概率最大的那一种作为最佳句子结构

## 词向量

第一种应用是找同义词。具体应用案例就是google的word2vec工具，通过训练好的词向量，指定一个词，可以返回和它cos距离最相近的词并排序。

第二种应用是词性标注和语义角色标注任务。具体使用方法是：把词向量作为神经网络的输入层，通过前馈网络和卷积网络完成。

第三种应用是句法分析和情感分析任务。具体使用方法是：把词向量作为递归神经网络的输入。

第四种应用是命名实体识别和短语识别。具体使用方法是：把词向量作为扩展特征使用。

另外词向量有一个非常特别的现象：C(king)-C(queue)≈C(man)-C(woman)，这里的减法就是向量逐维相减，换个表达方式就是：C(king)-C(man)+C(woman)和它最相近的向量就是C(queue)，这里面的原理其实就是：语义空间中的线性关系。基于这个结论相信会有更多奇妙的功能出现。

## 自动问答系统

CNN的三个优点：sparse interaction(稀疏的交互)，parameter sharing(参数共享)，equivalent respresentation(等价表示)。正是由于这三方面的优点，才更适合于自动问答系统中的答案选择模型的训练。

训练时获取问题的词向量Vq，和一个正向答案的词向量Va+，和一个负向答案的词向量Va-， 然后比较问题和这两个答案的相似度，两个相似度的差值如果大于一个阈值m就用来更新模型参数，然后继续在候选池里选答案，小于m就不更新模型

要把深度学习运用到聊天机器人中，关键在于以下几点：

1. 对几种神经网络结构的选择、组合、优化
2. 因为是有关自然语言处理，所以少不了能让机器识别的词向量
3. 当涉及到相似或匹配关系时要考虑相似度计算，典型的方法是cos距离
4. 如果需求涉及到文本序列的全局信息就用CNN或LSTM
5. 当精度不高时可以加层
6. 当计算量过大时别忘了参数共享和池化

论文：Applying Deep Learning To Answer Selection- A Study And An Open Task
